{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用Mahalanobis detector进行异常检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers, optimizers, Sequential, metrics\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将2018年的数据作进一步拆分\n",
    "\n",
    "def judge_1(time):\n",
    "    time = time[:7].replace('-', '')\n",
    "    if time <= '201803':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def judge_2(time):\n",
    "    time = time[:7].replace('-', '')\n",
    "    if time > '201803':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "data_csv = pd.read_csv('../../../csv/dataset.csv')\n",
    "data_2017 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2017']\n",
    "data_2018 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2018']\n",
    "data_2019 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2019']\n",
    "data_2018_1 = data_2018[data_2018['first_seen'].apply(judge_1)]\n",
    "data_2018_2 = data_2018[data_2018['first_seen'].apply(judge_2)]\n",
    "\n",
    "data_train = data_2017\n",
    "data_test_1 = data_2018_1\n",
    "data_test_2 = data_2018_2\n",
    "data_test_3 = data_2019\n",
    "\n",
    "data_train = data_train.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "data_test_1 = data_test_1.sample(frac=0.3, random_state=1).reset_index(drop=True)\n",
    "data_test_2 = data_test_2.sample(frac=0.3, random_state=1).reset_index(drop=True)\n",
    "data_test_3 = data_test_3.sample(frac=0.3, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2label = {'trojan':0, 'virus':1, 'worm':2, 'backdoor':3}\n",
    "\n",
    "# 训练数据\n",
    "codes_train = data_train['name'].to_list()\n",
    "labels_train = data_train['label'].map(lambda x: name2label[x])\n",
    "labels_train = labels_train.to_list()\n",
    "# 2018-03测试数据\n",
    "codes_test_1 = data_test_1['name'].to_list()\n",
    "labels_test_1 = data_test_1['label'].map(lambda x: name2label[x])\n",
    "labels_test_1 = labels_test_1.to_list()\n",
    "# 2018-06测试数据\n",
    "codes_test_2 = data_test_2['name'].to_list()\n",
    "labels_test_2 = data_test_2['label'].map(lambda x: name2label[x])\n",
    "labels_test_2 = labels_test_2.to_list()\n",
    "# 2019测试数据\n",
    "codes_test_3 = data_test_3['name'].to_list()\n",
    "labels_test_3 = data_test_3['label'].map(lambda x: name2label[x])\n",
    "labels_test_3 = labels_test_3.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(res, max_len=200000):\n",
    "    length = len(res)\n",
    "    if length > max_len:\n",
    "        return res[ :max_len]\n",
    "    elif length < max_len:\n",
    "        return res + [0]*(max_len-length)\n",
    "    return res\n",
    "\n",
    "def load_test_data(codes, labels):\n",
    "    \n",
    "    labels = np.eye(4)[labels]\n",
    "    res_all = []\n",
    "    for idx in tqdm(range(len(codes))):\n",
    "        fn = codes[idx]\n",
    "        fn = '../../../dataset/' + fn[8: ]\n",
    "        if not os.path.isfile(fn):\n",
    "            print(fn, 'not exist')\n",
    "        else:\n",
    "            with open(fn, 'rb') as f:\n",
    "                res = f.read()\n",
    "                res = [byte for byte in res]\n",
    "                res = pad_data(res)\n",
    "                res_all.append(res)\n",
    "    return np.array(res_all), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                               | 19/3476 [00:03<09:16,  6.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-50f1429ab7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlayer_model_8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcodes_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfeature_train_7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_model_7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfeature_train_8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_model_8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodes_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-0165a7210679>\u001b[0m in \u001b[0;36mload_test_data\u001b[1;34m(codes, labels)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbyte\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbyte\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mres_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-0165a7210679>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbyte\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbyte\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mres_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 加载预训练模型\n",
    "model = keras.models.load_model('../model/malconv_1.h5')\n",
    "\n",
    "# 得到第七层、第八层的模型\n",
    "layer_model_7 = Model(inputs=model.input, outputs=model.layers[7].output)\n",
    "layer_model_8 = Model(inputs=model.input, outputs=model.layers[8].output)\n",
    "\n",
    "codes_train, labels_train = load_test_data(codes_train, labels_train)\n",
    "feature_train_7 = layer_model_7.predict(codes_train)\n",
    "feature_train_8 = layer_model_8.predict(codes_train)\n",
    "\n",
    "# 将结果保存为文件\n",
    "\n",
    "np.save('feature_train_7.npy', feature_train_7)\n",
    "np.save('feature_train_8.npy', feature_train_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "model = keras.models.load_model('../model/malconv_1.h5')\n",
    "\n",
    "# 得到第七层、第八层的模型\n",
    "layer_model_7 = Model(inputs=model.input, outputs=model.layers[7].output)\n",
    "layer_model_8 = Model(inputs=model.input, outputs=model.layers[8].output)\n",
    "\n",
    "feature_7 = np.load('feature_train_7.npy')\n",
    "feature_8 = np.load('feature_train_8.npy')\n",
    "\n",
    "feature_train_7 = feature_7[: 2476]\n",
    "feature_val_7 = feature_7[2476: ]\n",
    "feature_train_8 = feature_8[: 2476]\n",
    "feature_val_8 = feature_8[2476:]\n",
    "\n",
    "data_feature = [feature_train_7, feature_train_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.covariance\n",
    "\n",
    "\n",
    "num_classes = 4\n",
    "group_lasso = sklearn.covariance.EmpiricalCovariance(assume_centered=False)\n",
    "num_output = len(data_feature)    # 值为2，即层的个数\n",
    "num_sample_per_class = np.empty(num_classes)\n",
    "num_sample_per_class.fill(0)\n",
    "list_features = []                # 第一个维度是层，第二个维度是类别，所以是2x4\n",
    "for i in range(num_output):\n",
    "    temp_list = []\n",
    "    for j in range(num_classes):\n",
    "        temp_list.append(0)\n",
    "    list_features.append(temp_list)\n",
    "\n",
    "\n",
    "for idx in range(len(data_feature[0])):\n",
    "    out_features = [feature_train_7[idx], feature_train_8[idx]]\n",
    "    label = labels_train[idx]\n",
    "    if num_sample_per_class[label] == 0:\n",
    "        out_count = 0\n",
    "        for out in out_features:\n",
    "            out = out[np.newaxis, :]\n",
    "            list_features[out_count][label] = out\n",
    "            out_count += 1\n",
    "    else:\n",
    "        out_count = 0\n",
    "        for out in out_features:\n",
    "            out = out[np.newaxis, :]\n",
    "            list_features[out_count][label] \\\n",
    "            = np.concatenate((list_features[out_count][label], out), axis=0)\n",
    "            out_count += 1\n",
    "    num_sample_per_class[label] += 1  \n",
    "\n",
    "# list_feature的行代表层，列代表类别，元素为一个二维矩阵，矩阵由每个样本对应的特征向量以行的形式拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从样本数目维度求均值，对于每一个类别都得到128维和64维的向量\n",
    "\n",
    "sample_class_mean = []            # 它的元素代表每个类别对应的求均值后的特征向量\n",
    "out_count = 0\n",
    "for num_feature in [128, 64]:\n",
    "    temp_list = []\n",
    "    for j in range(num_classes):\n",
    "        temp_list.append(np.mean(list_features[out_count][j], axis=0))\n",
    "    temp_list = np.array(temp_list)\n",
    "    sample_class_mean.append(temp_list)\n",
    "    out_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = []\n",
    "for k in range(num_output):\n",
    "    X = 0\n",
    "    for i in range(num_classes):\n",
    "        if i == 0:\n",
    "            X = list_features[k][i] - sample_class_mean[k][i]\n",
    "        else:\n",
    "            X = np.concatenate((X, list_features[k][i] - sample_class_mean[k][i]), axis=0)\n",
    "    \n",
    "    group_lasso.fit(X)\n",
    "    temp_precision = group_lasso.precision_\n",
    "    precision.append(temp_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Mahalanobis_score(codes_test, num_classes, sample_mean, \\\n",
    "                          layer_index, out_flag, precision):\n",
    "    \n",
    "    Mahalanobis = []\n",
    "    if out_flag == True:\n",
    "        temp_file_name = './confidence_Ga%s_In.txt'%(str(layer_index))\n",
    "    else:\n",
    "        temp_file_name = './confidence_Ga%s_Out.txt'%(str(layer_index))\n",
    "    \n",
    "    g = open(temp_file_name, 'w')\n",
    "    \n",
    "    # 计算Mahalanobis score\n",
    "    gaussian_score = 0\n",
    "    for i in range(num_classes):\n",
    "        batch_sample_mean = sample_mean[layer_index][i]    # 得到该类别下的样本均值向量\n",
    "        zero_f = codes_test - batch_sample_mean\n",
    "        term_gau = -0.5*np.dot(np.dot(zero_f, precision[layer_index]), zero_f.T).diagonal()\n",
    "        if i == 0:\n",
    "            gaussian_score = term_gau.reshape(-1, 1)\n",
    "        else:\n",
    "            # 以列向量进行拼接\n",
    "            gaussian_score = np.concatenate((gaussian_score, term_gau.reshape(-1, 1)), axis=1)\n",
    "            \n",
    "    gaussian_score = np.max(gaussian_score, axis=1)         # 它是一个二维矩阵，行向量代表的是样本在每个类别的score\n",
    "    Mahalanobis.extend(gaussian_score)\n",
    "    \n",
    "    for i in range(len(codes_test)):\n",
    "        g.write(\"{}\\n\".format(gaussian_score[i]))\n",
    "    g.close()\n",
    "    \n",
    "    return Mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-34-df9399094ec9>(15)get_Mahalanobis_score()\n",
      "-> for i in range(num_classes):\n"
     ]
    }
   ],
   "source": [
    "# 得到验证数据的score\n",
    "\n",
    "val_all = [feature_val_7, feature_val_8]\n",
    "for i in range(num_output):\n",
    "    \n",
    "    M_in = get_Mahalanobis_score(val_all[i], 4, sample_class_mean, i, True, precision)\n",
    "    M_in = np.asarray(M_in, dtype=np.float32)\n",
    "    if i == 0:\n",
    "        Mahalanobis_in = M_in.reshape((M_in.shape[0], -1))\n",
    "    else:\n",
    "        Mahalanobis_in = np.concatenate((Mahalanobis_in, M_in.reshape((M_in.shape[0], -1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
