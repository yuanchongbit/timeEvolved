{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用OCSVM进行novelty detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, Sequential, metrics\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6104, 5) (2642, 5) (3656, 5)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "def judge_1(time):\n",
    "    time = time[:7].replace('-', '')\n",
    "    if time <= '201803':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def judge_2(time):\n",
    "    time = time[:7].replace('-', '')\n",
    "    if time > '201803':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "name2label = {'trojan':0, 'virus':1, 'worm':2, 'backdoor':3}\n",
    "data_csv = pd.read_csv('res_handle.csv')\n",
    "data_2017 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2017']\n",
    "data_2018 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2018']\n",
    "data_2019 = data_csv[data_csv['first_seen'].apply(lambda x: x[:4]) == '2019']\n",
    "    \n",
    "data_2018_1 = data_2018[data_2018['first_seen'].apply(judge_1)]\n",
    "data_2018_2 = data_2018[data_2018['first_seen'].apply(judge_2)]\n",
    "\n",
    "data_train = data_2017.append(data_2018_１)\n",
    "data_test_1 = data_2018_２\n",
    "data_test_2 = data_2019\n",
    "print(data_train.shape, data_test_1.shape, data_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6104, 5) (1849, 5) (1828, 5)\n"
     ]
    }
   ],
   "source": [
    "# 对测试集进行下采样\n",
    "data_train = data_train.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "data_test_1 = data_test_1.sample(frac=0.7, random_state=1).reset_index(drop=True)\n",
    "data_test_2 = data_test_2.sample(frac=0.5, random_state=1).reset_index(drop=True)\n",
    "print(data_train.shape, data_test_1.shape, data_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "data_path_1, labels_1 = path_loader(data_train)\n",
    "data_path_2, labels_2 = path_loader(data_test_1)\n",
    "data_path_3, labels_3 = path_loader(data_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12402/12402 [00:06<00:00, 1839.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用labelencoder构建opcode编码器\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "opcode_all = []\n",
    "for idx in tqdm(range(data_csv.shape[0])):\n",
    "    opcode_str = data_csv.at[idx, 'opcode'].split()\n",
    "    opcode_all += opcode_str\n",
    "    opcode_all = list(set(opcode_all))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(opcode_all)\n",
    "len(list(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_loader(codes, labels, mode):\n",
    "    \n",
    "    if mode == 'train':    \n",
    "        codes = codes[: 5100]\n",
    "        labels = labels[: 5100]\n",
    "    elif mode == 'val':    \n",
    "        codes = codes[5100: ]\n",
    "        labels = labels[5100: ]\n",
    "    \n",
    "    labels_res = np.eye(4)[labels]\n",
    "    res_all = []\n",
    "    for idx in tqdm(range(len(codes))):\n",
    "        fn = codes[idx]\n",
    "        op_string = data_csv[data_csv.name == fn]\n",
    "        op_string = op_string.iloc[0, 1].split()\n",
    "        res = list(le.transform(op_string))\n",
    "        res = pad_data(res)\n",
    "        res_all.append(res)\n",
    "    return np.array(res_all), labels_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6104/6104 [00:27<00:00, 222.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "model = keras.models.load_model('./model/textcnn_split.h5')\n",
    "codes_train, labels_train = train_data_loader(data_path_1, labels_1, 'test')\n",
    "layer_model = Model(inputs=model.input, outputs=model.layers[12].output)\n",
    "feature_train = layer_model.predict(codes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将特征向量保存为文件\n",
    "np.save('feature_train.npy', feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6104, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1411, 6), (1804, 6), (1324, 6), (1565, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['vector'] = ''\n",
    "for idx in range(data_train.shape[0]):\n",
    "    data_train.at[idx, 'vector'] = list(feature_train[idx])\n",
    "    \n",
    "data_backdoor = data_train[data_train['label']=='backdoor']\n",
    "data_virus = data_train[data_train['label']=='virus']\n",
    "data_worm = data_train[data_train['label']=='worm']\n",
    "data_trojan = data_train[data_train['label']=='trojan']\n",
    "\n",
    "data_backdoor.shape, data_virus.shape, data_worm.shape, data_trojan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backdoor = np.array(data_backdoor['vector'].to_list())\n",
    "data_backdoor_train = data_backdoor[: 1200]\n",
    "data_backdoor_val = data_backdoor[1200: ]\n",
    "\n",
    "data_virus = np.array(data_virus['vector'].to_list())\n",
    "data_virus_train = data_virus[: 1600]\n",
    "data_virus_val = data_virus[1600: ]\n",
    "\n",
    "data_worm = np.array(data_worm['vector'].to_list())\n",
    "data_worm_train = data_worm[: 1100]\n",
    "data_worm_val = data_worm[1100: ]\n",
    "\n",
    "data_trojan = np.array(data_trojan['vector'].to_list())\n",
    "data_trojan_train = data_trojan[: 1300]\n",
    "data_trojan_val = data_trojan[1300: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "def percen(arr):\n",
    "    num = sum(arr==1)\n",
    "    return num / arr.size\n",
    "\n",
    "one_svm_backdoor = OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='scale').fit(data_backdoor_train)\n",
    "percen(one_svm_backdoor.predict(data_backdoor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_svm_virus = OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='scale').fit(data_virus_train)\n",
    "percen(one_svm_virus.predict(data_virus_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821428571428571"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_svm_worm = OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='scale').fit(data_worm_train)\n",
    "percen(one_svm_worm.predict(data_worm_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_svm_trojan = OneClassSVM(nu=0.001, kernel=\"rbf\", gamma='scale').fit(data_trojan_train)\n",
    "percen(one_svm_trojan.predict(data_trojan_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1849/1849 [00:13<00:00, 137.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1454, 6)\n"
     ]
    }
   ],
   "source": [
    "# 对第一个测试子集进行novelty detection\n",
    "codes_test_1, labels_test_1 = path_loader(data_test_1)\n",
    "codes_test_1, labels_test_1 = train_data_loader(codes_test_1, labels_test_1, 'test')\n",
    "feature_test = layer_model.predict(codes_test_1)\n",
    "data_test_1['novelty'] = ''\n",
    "\n",
    "res_1 = one_svm_backdoor.predict(feature_test)\n",
    "res_2 = one_svm_virus.predict(feature_test)\n",
    "res_3 = one_svm_worm.predict(feature_test)\n",
    "res_4 = one_svm_trojan.predict(feature_test)\n",
    "\n",
    "for idx in range(data_test_1.shape[0]):\n",
    "    res = res_1[idx]+res_2[idx]+res_3[idx]+res_4[idx]\n",
    "    if res == -4 or res >= 0:\n",
    "        data_test_1.at[idx, 'novelty'] = 1\n",
    "    else:\n",
    "        data_test_1.at[idx, 'novelty'] = 0\n",
    "        \n",
    "data_normal = data_test_1[data_test_1['novelty']==0]\n",
    "print(data_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1454/1454 [00:10<00:00, 133.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      trojan       0.99      1.00      0.99       455\n",
      "    backdoor       0.99      1.00      1.00       521\n",
      "       virus       1.00      0.88      0.94       150\n",
      "        worm       0.95      0.98      0.96       328\n",
      "\n",
      "    accuracy                           0.98      1454\n",
      "   macro avg       0.98      0.96      0.97      1454\n",
      "weighted avg       0.98      0.98      0.98      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "codes_normal, labels_normal = path_loader(data_normal)\n",
    "codes_normal, labels_normal = train_data_loader(codes_normal, labels_normal, 'test')\n",
    "\n",
    "y_pred = model.predict(codes_normal)\n",
    "y_true = np.argmax(labels_normal, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "target_names = {'trojan', 'virus', 'worm', 'backdoor'}\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型预测错误的数据标注为OOD数据\n",
    "\n",
    "test_pred_1 = model.predict(codes_test_1)\n",
    "test_pred_1 = np.argmax(test_pred_1, axis=1)\n",
    "test_true_1 = np.argmax(labels_test_1, axis=1)\n",
    "bool_pred = np.equal(test_pred_1, test_true_1)\n",
    "data_test_1['id'] = bool_pred\n",
    "data_test_1.to_csv('data_test_1.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1643\n",
      "           1       0.45      0.87      0.60       206\n",
      "\n",
      "    accuracy                           0.87      1849\n",
      "   macro avg       0.72      0.87      0.76      1849\n",
      "weighted avg       0.92      0.87      0.89      1849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算ocsvm识别的准确率\n",
    "\n",
    "svm_pred = np.array(data_test_1['novelty'])\n",
    "svm_pred = svm_pred.astype('int64')\n",
    "ood2label = {True: 0, False: 1}\n",
    "label_id = np.array(data_test_1['id'].map(lambda x: ood2label[x]))\n",
    "print(classification_report(label_id, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1828/1828 [00:06<00:00, 304.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1123, 6)\n"
     ]
    }
   ],
   "source": [
    "# 对第二个测试子集进行novelty detection\n",
    "codes_test_２, labels_test_２ = path_loader(data_test_２)\n",
    "codes_test_２, labels_test_２ = train_data_loader(codes_test_２, labels_test_２, 'test')\n",
    "feature_test_２ = layer_model.predict(codes_test_２)\n",
    "data_test_２['novelty'] = ''\n",
    "\n",
    "res_1 = one_svm_backdoor.predict(feature_test_２)\n",
    "res_2 = one_svm_virus.predict(feature_test_２)\n",
    "res_3 = one_svm_worm.predict(feature_test_２)\n",
    "res_4 = one_svm_trojan.predict(feature_test_２)\n",
    "\n",
    "for idx in range(data_test_２.shape[0]):\n",
    "    res = res_1[idx]+res_2[idx]+res_3[idx]+res_4[idx]\n",
    "    if res == -4 or res >= 0:\n",
    "        data_test_２.at[idx, 'novelty'] = 1\n",
    "    else:\n",
    "        data_test_２.at[idx, 'novelty'] = 0\n",
    "        \n",
    "data_normal = data_test_２[data_test_２['novelty']==0]\n",
    "print(data_normal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1123/1123 [00:04<00:00, 262.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    backdoor       0.99      0.80      0.88       292\n",
      "        worm       0.86      1.00      0.92       319\n",
      "      trojan       0.98      0.88      0.93       182\n",
      "       virus       0.94      1.00      0.97       330\n",
      "\n",
      "    accuracy                           0.93      1123\n",
      "   macro avg       0.94      0.92      0.93      1123\n",
      "weighted avg       0.94      0.93      0.93      1123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "codes_normal, labels_normal = path_loader(data_normal)\n",
    "codes_normal, labels_normal = train_data_loader(codes_normal, labels_normal, 'test')\n",
    "\n",
    "y_pred = model.predict(codes_normal)\n",
    "y_true = np.argmax(labels_normal, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "target_names = {'trojan', 'virus', 'worm', 'backdoor'}\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79      1505\n",
      "           1       0.34      0.75      0.47       323\n",
      "\n",
      "    accuracy                           0.70      1828\n",
      "   macro avg       0.64      0.72      0.63      1828\n",
      "weighted avg       0.83      0.70      0.74      1828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 将模型预测错误的数据标注为OOD数据\n",
    "\n",
    "test_pred_2 = model.predict(codes_test_2)\n",
    "test_pred_2 = np.argmax(test_pred_2, axis=1)\n",
    "test_true_2 = np.argmax(labels_test_2, axis=1)\n",
    "bool_pred = np.equal(test_pred_2, test_true_2)\n",
    "data_test_2['id'] = bool_pred\n",
    "data_test_2.to_csv('data_test_2.csv', index=0)\n",
    "\n",
    "# 计算ocsvm识别的准确率\n",
    "\n",
    "svm_pred = np.array(data_test_2['novelty'])\n",
    "svm_pred = svm_pred.astype('int64')\n",
    "ood2label = {True: 0, False: 1}\n",
    "label_id = np.array(data_test_2['id'].map(lambda x: ood2label[x]))\n",
    "print(classification_report(label_id, svm_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
